{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet Success: Analyzing Recipe Ratings with Data Science\n",
    "\n",
    "**Name(s)**: Timothy Kam\n",
    "\n",
    "**Website Link**: https://psionergy.github.io/recipe-analysis-project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "#from dsc80_utils import * # Feel free to uncomment and use this.\n",
    "\n",
    "recipes = pd.read_csv('food_data/RAW_recipes.csv')\n",
    "ratings = pd.read_csv('food_data/RAW_interactions.csv')\n",
    "ratings_dist = ratings['rating'].value_counts().sort_index()\n",
    "\n",
    "# Generate a bar plot of ratings distribution\n",
    "fig = px.bar(\n",
    "    x=ratings_dist.index,\n",
    "    y=ratings_dist.values,\n",
    "    labels={'x': 'Rating', 'y': 'Count'},\n",
    "    title='Distribution of Ratings'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Introduction and Question Identification\n",
    "\n",
    "## Dataset Introduction\n",
    "## The dataset I am working with is the **Recipes and Ratings** dataset. It contains information about recipes, their preparation times, ingredients, user ratings, and reviews.\n",
    "\n",
    "## Central Question\n",
    "## How do the number of ingredients and preparation time affect recipe ratings?*\n",
    "\n",
    "## Why It Matters\n",
    "## Understanding these relationships can help recipe creators optimize their content for better user satisfaction. It also sheds light on user behavior and preferences in cooking.\n",
    "\n",
    "### Relevant Columns\n",
    "## - `rating`: User rating of the recipe (target variable).\n",
    "## - `n_ingredients`: Number of ingredients in a recipe.\n",
    "## - `minutes`: Preparation time for the recipe.\n",
    "\n",
    "### Dataset Overview\n",
    "## ```python\n",
    "# Display basic information about the dataset\n",
    "print(f\"Recipes Dataset: {recipes.shape[0]} rows, {recipes.shape[1]} columns\")\n",
    "print(f\"Ratings Dataset: {ratings.shape[0]} rows, {ratings.shape[1]} columns\")\n",
    "\n",
    "# Show the first few rows\n",
    "print(\"Recipes Dataset Head:\")\n",
    "display(recipes.head())\n",
    "\n",
    "print(\"\\nRatings Dataset Head:\")\n",
    "display(ratings.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "### Data Cleaning\n",
    "### The following data cleaning steps were performed to ensure the dataset was ready for analysis:\n",
    "\n",
    "### 1. **Handled Missing Values**:\n",
    "###   - Replaced invalid values (`'?'`, `'NA'`, `'null'`) with `NaN`.\n",
    "###   - Converted the `date` column in the ratings dataset to a datetime object.\n",
    "\n",
    "### 2. **Ensured Numeric Columns**:\n",
    "###  - Ensured columns such as `n_ingredients` and `rating` were numeric for accurate analysis.\n",
    "\n",
    "### 3. **Removed Duplicates**:\n",
    "##   - Removed duplicate rows in both the `recipes` and `ratings` datasets.\n",
    "\n",
    "### These cleaning steps ensured that the data was consistent and ready for further analysis. \n",
    "###\n",
    "# # Replace invalid values with NaN\n",
    "recipes.replace(['?', 'NA', 'null'], np.nan, inplace=True)\n",
    "ratings.replace(['?', 'NA', 'null'], np.nan, inplace=True)\n",
    "\n",
    "# Convert 'date' column in ratings to datetime\n",
    "ratings['date'] = pd.to_datetime(ratings['date'])\n",
    "\n",
    "# Drop duplicates\n",
    "recipes = recipes.drop_duplicates()\n",
    "ratings = ratings.drop_duplicates()\n",
    "\n",
    "# Ensure numeric columns\n",
    "recipes['n_ingredients'] = pd.to_numeric(recipes['n_ingredients'], errors='coerce')\n",
    "ratings['rating'] = pd.to_numeric(ratings['rating'], errors='coerce')\n",
    "\n",
    "# Display cleaned data\n",
    "print(\"Cleaned Recipes Dataset:\")\n",
    "display(recipes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Univariate Analysis\n",
    "\n",
    "##1. **Distribution of Ratings**:\n",
    " ##  - Most recipes receive ratings of 4 or 5, indicating a positive user bias.\n",
    "\n",
    "##2. **Distribution of Preparation Times**:\n",
    " ##  - Majority of recipes take under 60 minutes to prepare.\n",
    "\n",
    "\n",
    "# Plot 1: Distribution of Ratings\n",
    "##ratings_dist = ratings['rating'].value_counts().sort_index()\n",
    "fig1 = px.bar(\n",
    "    x=ratings_dist.index,\n",
    "    y=ratings_dist.values,\n",
    "    labels={'x': 'Rating', 'y': 'Count'},\n",
    "    title='Distribution of Ratings'\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter the data to include only preparation times within the 0â€“300 range\n",
    "filtered_recipes = recipes[recipes['minutes'] <= 300]\n",
    "\n",
    "# Plot the histogram for preparation times in the filtered range\n",
    "fig = px.histogram(\n",
    "    filtered_recipes,\n",
    "    x='minutes',\n",
    "    nbins=50,\n",
    "    title='Distribution of Recipe Preparation Times (0-300 Minutes)',\n",
    "    labels={'minutes': 'Preparation Time (Minutes)', 'count': 'Recipe Count'}\n",
    ")\n",
    "\n",
    "# Update the layout with explicit axis labels and formatting\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Preparation Time (Minutes)\",\n",
    "    yaxis_title=\"Number of Recipes\",\n",
    "    xaxis=dict(range=[0, 300])  # Set the range explicitly\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# Save the first graph (ratings distribution) to an HTML file\n",
    "fig1.write_html('assets/ratings_distribution.html', include_plotlyjs='cdn')\n",
    "\n",
    "# Save the second graph (preparation times) to an HTML file\n",
    "fig.write_html('assets/preparation_times.html', include_plotlyjs='cdn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bivariate Analysis\n",
    "\n",
    "##1. **Number of Ingredients vs. Preparation Time**:\n",
    "##   - Recipes with more ingredients tend to take longer to prepare.\n",
    "\n",
    "##2. **Ratings by Year**:\n",
    "##   - Ratings have been consistently high over the years.\n",
    "\n",
    "\n",
    "# Plot 1: Ingredients vs. Preparation Time\n",
    "# Plot 1: Ingredients vs. Preparation Time\n",
    "fig3 = px.scatter(\n",
    "    recipes,\n",
    "    x='n_ingredients',\n",
    "    y='minutes',\n",
    "    title='Ingredients vs. Preparation Time',\n",
    "    labels={'x': 'Number of Ingredients', 'y': 'Preparation Time (minutes)'}\n",
    ")\n",
    "fig3.show()\n",
    "\n",
    "# Ensure 'date' column is in datetime format\n",
    "ratings['date'] = pd.to_datetime(ratings['date'], errors='coerce')\n",
    "\n",
    "# Extract the year from the 'date' column\n",
    "ratings['year'] = ratings['date'].dt.year\n",
    "\n",
    "# Plot 2: Ratings by Year\n",
    "fig4 = px.box(\n",
    "    ratings,\n",
    "    x='year',\n",
    "    y='rating',\n",
    "    title='Ratings by Year',\n",
    "    labels={'x': 'Year', 'y': 'Rating'}\n",
    ")\n",
    "fig4.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create a Markdown table\n",
    "def generate_markdown_table(df, num_rows=10):\n",
    "    # Get the first few rows of the DataFrame\n",
    "    rows = df.head(num_rows).values.tolist()\n",
    "    # Get the column headers\n",
    "    headers = df.columns.tolist()\n",
    "    \n",
    "    # Start with the header row\n",
    "    markdown = \"| \" + \" | \".join(headers) + \" |\\n\"\n",
    "    markdown += \"| \" + \" | \".join([\"---\"] * len(headers)) + \" |\\n\"\n",
    "    \n",
    "    # Add each row of data\n",
    "    for row in rows:\n",
    "        markdown += \"| \" + \" | \".join(map(str, row)) + \" |\\n\"\n",
    "    \n",
    "    return markdown\n",
    "\n",
    "# Generate the Markdown table for the interesting aggregates\n",
    "markdown_table = generate_markdown_table(interesting_aggregates)\n",
    "\n",
    "# Print the Markdown table\n",
    "print(markdown_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assessment of Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "## Step 3: Assessment of Missingness\n",
    "\n",
    "### NMAR Analysis\n",
    "##The column `review` may be NMAR since missing reviews could depend on user behavior (e.g., users who dislike a recipe may skip leaving a review).\n",
    "\n",
    "### Missingness Dependency\n",
    "##Test whether missingness in `review` is dependent on `rating`.\n",
    "\n",
    "\n",
    "# Test for dependency\n",
    "missing_reviews = ratings['review'].isnull()\n",
    "obs_diff = ratings.groupby(missing_reviews)['rating'].mean()\n",
    "\n",
    "# Permutation Test\n",
    "np.random.seed(0)\n",
    "perm_diffs = []\n",
    "for _ in range(1000):\n",
    "    shuffled = ratings['rating'].sample(frac=1).reset_index(drop=True)\n",
    "    perm_diff = shuffled[missing_reviews].mean() - shuffled[~missing_reviews].mean()\n",
    "    perm_diffs.append(perm_diff)\n",
    "\n",
    "# Plot Permutation Results\n",
    "fig = px.histogram(\n",
    "    perm_diffs,\n",
    "    title='Permutation Test: Missingness in Reviews vs Ratings',\n",
    "    labels={'x': 'Difference in Means'}\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "## Step 4: Hypothesis Testing\n",
    "\n",
    "## **New Hypotheses**:\n",
    "# - Null: Recipes with high sugar content (above the median) have the same ratings as those with low sugar content.\n",
    "# - Alternative: Recipes with high sugar content have different ratings than those with low sugar content.\n",
    "\n",
    "# Extract sugar content from the 'nutrition' column (assuming it's in a list or string format)\n",
    "# If 'nutrition' is a string like \"[calories, sugar, fat, ...]\", extract the sugar column\n",
    "recipes['sugar'] = recipes['nutrition'].apply(lambda x: float(x.strip('[]').split(',')[1]) if pd.notnull(x) else None)\n",
    "\n",
    "# Merge the DataFrames on recipe_id\n",
    "merged_df = pd.merge(ratings, recipes, left_on='recipe_id', right_on='id', how='inner')\n",
    "\n",
    "# Categorize recipes into low and high sugar groups based on the median\n",
    "sugar_median = merged_df['sugar'].median()\n",
    "low_sugar = merged_df[merged_df['sugar'] <= sugar_median]['rating']\n",
    "high_sugar = merged_df[merged_df['sugar'] > sugar_median]['rating']\n",
    "\n",
    "# Check descriptive statistics for both groups\n",
    "print(f\"Low Sugar Ratings: {low_sugar.describe()}\")\n",
    "print(f\"High Sugar Ratings: {high_sugar.describe()}\")\n",
    "\n",
    "# Perform the T-Test\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_val = ttest_ind(low_sugar, high_sugar, nan_policy='omit')\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_val}\")\n",
    "\n",
    "mean_diff = low_sugar.mean() - high_sugar.mean()\n",
    "pooled_sd = np.sqrt((low_sugar.var() + high_sugar.var()) / 2)\n",
    "cohens_d = mean_diff / pooled_sd\n",
    "print(f\"Cohen's d: {cohens_d}\")\n",
    "\n",
    "# Categorize recipes for visualization\n",
    "merged_df['sugar_category'] = merged_df['sugar'].apply(lambda x: 'Low Sugar' if x <= sugar_median else 'High Sugar')\n",
    "\n",
    "# Create a boxplot\n",
    "import plotly.express as px\n",
    "fig = px.box(\n",
    "    merged_df,\n",
    "    x='sugar_category',\n",
    "    y='rating',\n",
    "    title='Ratings by Sugar Content',\n",
    "    labels={'sugar_category': 'Sugar Content Category', 'rating': 'Rating'}\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Step 5: Framing a Prediction Problem\n",
    "\n",
    "# ## Prediction Problem\n",
    "# I will predict recipe preparation time (in minutes) based on recipe characteristics.\n",
    "\n",
    "# ## Type of Prediction\n",
    "# This is a regression problem since we are predicting a continuous numerical value (minutes of preparation time).\n",
    "\n",
    "# ## Response Variable\n",
    "# The response variable is 'minutes' (preparation time) from the recipes dataset. I chose this because:\n",
    "# 1. It's an objective measure that's directly influenced by recipe features\n",
    "# 2. Has clear cause-and-effect relationships with characteristics like number of ingredients and steps\n",
    "# 3. Provides practical value to users planning their cooking time\n",
    "\n",
    "# ## Features Available at Prediction Time\n",
    "# We can use recipe characteristics that would be known before cooking:\n",
    "# - n_ingredients: Number of ingredients\n",
    "# - n_steps: Number of steps\n",
    "# - nutrition: Nutritional information\n",
    "# - Description and tag information\n",
    "\n",
    "# We cannot use features that would only be known after cooking, such as:\n",
    "# - User ratings\n",
    "# - Reviews\n",
    "# - User interactions\n",
    "\n",
    "# ## Evaluation Metric\n",
    "# I will use Root Mean Squared Error (RMSE) to evaluate the model because:\n",
    "# 1. It's appropriate for regression problems\n",
    "# 2. Provides error in the same units as our prediction (minutes)\n",
    "# 3. Penalizes larger errors more heavily, which is important for time predictions\n",
    "# 4. Easy to interpret - tells us how far off our time predictions are on average\n",
    "\n",
    "## Initial Investigation\n",
    "# Let's look at some basic statistics about preparation time:\n",
    "\n",
    "# Our target variable statistics show:\n",
    "# 1. Preparation times range from 0 to 1,051,200 minutes (about 2 years)\n",
    "# 2. Most recipes take between 20-65 minutes (25th to 75th percentile)\n",
    "# 3. The median preparation time is 35 minutes\n",
    "# 4. There are clear outliers in the data, as indicated by:\n",
    "#    - Very high maximum value (over 2 years)\n",
    "#    - Large difference between mean (115 minutes) and median (35 minutes)\n",
    "#    - Large standard deviation (3,991 minutes)\n",
    "\n",
    "# The correlations between preparation time and recipe features show:\n",
    "# - n_ingredients correlation: -0.008\n",
    "# - n_steps correlation: 0.008\n",
    "\n",
    "# These very low correlations suggest we'll need to:\n",
    "# 1. Clean outliers from our preparation times\n",
    "# 2. Consider non-linear relationships\n",
    "# 3. Engineer features that better capture recipe complexity\n",
    "\n",
    "# This investigation will help inform our modeling choices in the subsequent steps.\n",
    "# Basic statistics of our target variable\n",
    "print(\"\\nPreparation Time Statistics (minutes):\")\n",
    "print(recipes['minutes'].describe())\n",
    "\n",
    "# Look at correlations with key features\n",
    "correlations = recipes[['minutes', 'n_ingredients', 'n_steps']].corr()['minutes']\n",
    "print(\"\\nCorrelations with preparation time:\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Ensure all necessary features are computed\n",
    "recipes['mean_ingredient_time'] = recipes['minutes'] / recipes['n_ingredients']\n",
    "recipes['ingredients_per_step'] = recipes['n_ingredients'] / recipes['n_steps']\n",
    "recipes['log_minutes'] = np.log1p(recipes['minutes'])\n",
    "\n",
    "# Step 2: Define features and target\n",
    "features = ['n_ingredients', 'n_steps', 'mean_ingredient_time', 'ingredients_per_step']\n",
    "target = 'log_minutes'\n",
    "\n",
    "# Step 3: Split dataset into training and testing sets\n",
    "X = recipes[features]\n",
    "y = recipes[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create pipeline with polynomial features\n",
    "baseline_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)),  # Add polynomial features\n",
    "    ('regressor', Ridge())  # Ridge regression\n",
    "])\n",
    "\n",
    "# Step 5: Hyperparameter tuning\n",
    "param_grid = {'regressor__alpha': [0.01, 0.1, 1, 10, 100]}  # Search for the best alpha (regularization strength)\n",
    "grid_search = GridSearchCV(baseline_pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Improved Baseline Model Performance (Ridge Regression with Polynomial Features):\")\n",
    "print(f\"Training MSE: {train_mse:.4f}\")\n",
    "print(f\"Testing MSE: {test_mse:.4f}\")\n",
    "print(f\"Training R^2: {train_r2:.4f}\")\n",
    "print(f\"Testing R^2: {test_r2:.4f}\")\n",
    "\n",
    "# Step 7: Display feature coefficients\n",
    "coefficients = best_model.named_steps['regressor'].coef_\n",
    "poly_features = best_model.named_steps['poly'].get_feature_names_out(features)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': poly_features,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Step 8: Best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Define features and target\n",
    "features = ['n_ingredients', 'n_steps', 'mean_ingredient_time', 'ingredients_per_step']\n",
    "target = 'log_minutes'\n",
    "\n",
    "# Ensure the dataset is split correctly\n",
    "X = recipes[features]\n",
    "y = recipes[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 1: Create the pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Polynomial features\n",
    "    ('regressor', RandomForestRegressor(random_state=42))  # Random Forest for better performance\n",
    "])\n",
    "\n",
    "# Step 2: Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100],\n",
    "    'regressor__max_depth': [5, 10],\n",
    "    'regressor__min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    final_pipeline, \n",
    "    param_grid, \n",
    "    cv=3, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Final Model Performance:\")\n",
    "print(f\"Training MSE: {train_mse:.4f}\")\n",
    "print(f\"Testing MSE: {test_mse:.4f}\")\n",
    "print(f\"Training R^2: {train_r2:.4f}\")\n",
    "print(f\"Testing R^2: {test_r2:.4f}\")\n",
    "\n",
    "# Step 4: Feature importance\n",
    "# Extract feature names from PolynomialFeatures\n",
    "polynomial_transformer = best_model.named_steps['poly']\n",
    "poly_features = polynomial_transformer.get_feature_names_out(features)\n",
    "\n",
    "# Extract feature importances from Random Forest\n",
    "importances = best_model.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# Align the lengths of feature names and importances\n",
    "if len(poly_features) != len(importances):\n",
    "    poly_features = poly_features[:len(importances)]\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': poly_features,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Step 5: Best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 1: Define groups\n",
    "median_ingredients = X_test['n_ingredients'].median()\n",
    "X_test['complexity_group'] = X_test['n_ingredients'].apply(\n",
    "    lambda x: 'Low Complexity' if x <= median_ingredients else 'High Complexity'\n",
    ")\n",
    "\n",
    "# Step 2: Predict using the final model\n",
    "y_test_pred = best_model.predict(X_test.drop(columns=['complexity_group']))\n",
    "\n",
    "# Step 3: Calculate RMSE for each group\n",
    "low_complexity_rmse = np.sqrt(mean_squared_error(\n",
    "    y_test[X_test['complexity_group'] == 'Low Complexity'], \n",
    "    y_test_pred[X_test['complexity_group'] == 'Low Complexity']\n",
    "))\n",
    "high_complexity_rmse = np.sqrt(mean_squared_error(\n",
    "    y_test[X_test['complexity_group'] == 'High Complexity'], \n",
    "    y_test_pred[X_test['complexity_group'] == 'High Complexity']\n",
    "))\n",
    "\n",
    "# Observed difference in RMSE\n",
    "observed_diff = np.abs(low_complexity_rmse - high_complexity_rmse)\n",
    "print(f\"Observed RMSE Difference: {observed_diff:.4f}\")\n",
    "\n",
    "# Step 4: Permutation test\n",
    "n_permutations = 1000\n",
    "perm_diffs = []\n",
    "\n",
    "# Combine true values and predictions\n",
    "test_data = pd.DataFrame({\n",
    "    'true': y_test,\n",
    "    'predicted': y_test_pred,\n",
    "    'complexity_group': X_test['complexity_group']\n",
    "})\n",
    "\n",
    "for _ in range(n_permutations):\n",
    "    # Shuffle group labels\n",
    "    shuffled = test_data.copy()\n",
    "    shuffled['complexity_group'] = np.random.permutation(shuffled['complexity_group'])\n",
    "\n",
    "    # Recalculate RMSE for permuted groups\n",
    "    low_complexity_rmse_perm = np.sqrt(mean_squared_error(\n",
    "        shuffled[shuffled['complexity_group'] == 'Low Complexity']['true'],\n",
    "        shuffled[shuffled['complexity_group'] == 'Low Complexity']['predicted']\n",
    "    ))\n",
    "    high_complexity_rmse_perm = np.sqrt(mean_squared_error(\n",
    "        shuffled[shuffled['complexity_group'] == 'High Complexity']['true'],\n",
    "        shuffled[shuffled['complexity_group'] == 'High Complexity']['predicted']\n",
    "    ))\n",
    "\n",
    "    # Store permuted RMSE difference\n",
    "    perm_diffs.append(np.abs(low_complexity_rmse_perm - high_complexity_rmse_perm))\n",
    "\n",
    "# Step 5: Calculate p-value\n",
    "perm_diffs = np.array(perm_diffs)\n",
    "p_value = np.mean(perm_diffs >= observed_diff)\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Step 6: Visualize the null distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(perm_diffs, bins=30, alpha=0.75, label='Null Distribution')\n",
    "plt.axvline(observed_diff, color='red', linestyle='dashed', linewidth=2, label='Observed Difference')\n",
    "plt.title('Permutation Test: RMSE Difference Between Groups')\n",
    "plt.xlabel('RMSE Difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 7: Conclusion\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: The model's performance differs significantly between the two groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference in model performance between the two groups.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
